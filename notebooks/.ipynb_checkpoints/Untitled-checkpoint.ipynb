{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83844dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbdfa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 2022\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c929e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('android.csv')\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddbf903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dataset['class']\n",
    "X = dataset.drop(['class'], axis=1)\n",
    "features = X.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e206ec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder = LabelEncoder().fit(Y)\n",
    "Y = encoder.transform(Y)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27a3e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array(X)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451a75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE before feature selection: 0.11\n"
     ]
    }
   ],
   "source": [
    "est = SVC()\n",
    "score = -1.0 * cross_val_score(est, X, Y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "print(\"CV MSE before feature selection: {:.2f}\".format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06e5b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticSelector():\n",
    "    def __init__(self, estimator, n_gen, size, n_best, n_rand, \n",
    "                 n_children, mutation_rate):\n",
    "        # Estimator \n",
    "        self.estimator = estimator\n",
    "        # Number of generations\n",
    "        self.n_gen = n_gen\n",
    "        # Number of chromosomes in population\n",
    "        self.size = size\n",
    "        # Number of best chromosomes to select\n",
    "        self.n_best = n_best\n",
    "        # Number of random chromosomes to select\n",
    "        self.n_rand = n_rand\n",
    "        # Number of children created during crossover\n",
    "        self.n_children = n_children\n",
    "        # Probablity of chromosome mutation\n",
    "        self.mutation_rate = mutation_rate\n",
    "        \n",
    "        if int((self.n_best + self.n_rand) / 2) * self.n_children != self.size:\n",
    "            raise ValueError(\"The population size is not stable.\")  \n",
    "            \n",
    "    def initilize(self):\n",
    "        population = []\n",
    "        for i in range(self.size):\n",
    "            chromosome = np.ones(self.n_features, dtype= bool)\n",
    "            mask = np.random.rand(len(chromosome)) < 0.3\n",
    "            chromosome[mask] = False\n",
    "            population.append(chromosome)\n",
    "        return population\n",
    "\n",
    "    def fitness(self, population):\n",
    "        X, y = self.dataset\n",
    "        scores = []\n",
    "        for chromosome in population:\n",
    "            score = -1.0 * np.mean(cross_val_score(self.estimator, X[:,chromosome], y, \n",
    "                                                       cv=5, \n",
    "                                                       scoring=\"neg_mean_squared_error\"))\n",
    "            scores.append(score)\n",
    "        scores, population = np.array(scores), np.array(population) \n",
    "        inds = np.argsort(scores)\n",
    "        return list(scores[inds]), list(population[inds,:])\n",
    "\n",
    "    def select(self, population_sorted):\n",
    "        population_next = []\n",
    "        for i in range(self.n_best):\n",
    "            population_next.append(population_sorted[i])\n",
    "        for i in range(self.n_rand):\n",
    "            population_next.append(random.choice(population_sorted))\n",
    "        random.shuffle(population_next)\n",
    "        return population_next\n",
    "\n",
    "    def crossover(self, population):\n",
    "        population_next = []\n",
    "        for i in range(int(len(population)/2)):\n",
    "            for j in range(self.n_children):\n",
    "                chromosome1, chromosome2 = population[i], population[len(population)-1-i]\n",
    "                child = chromosome1\n",
    "                mask = np.random.rand(len(child)) > 0.5\n",
    "                child[mask] = chromosome2[mask]\n",
    "                population_next.append(child)\n",
    "        return population_next\n",
    "\t\n",
    "    def mutate(self, population):\n",
    "        population_next = []\n",
    "        for i in range(len(population)):\n",
    "            chromosome = population[i]\n",
    "            if random.random() < self.mutation_rate:\n",
    "                mask = np.random.rand(len(chromosome)) < 0.05\n",
    "                chromosome[mask] = False\n",
    "            population_next.append(chromosome)\n",
    "        return population_next\n",
    "\n",
    "    def generate(self, population):\n",
    "        # Selection, crossover and mutation\n",
    "        scores_sorted, population_sorted = self.fitness(population)\n",
    "        population = self.select(population_sorted)\n",
    "        population = self.crossover(population)\n",
    "        population = self.mutate(population)\n",
    "        # History\n",
    "        self.chromosomes_best.append(population_sorted[0])\n",
    "        self.scores_best.append(scores_sorted[0])\n",
    "        self.scores_avg.append(np.mean(scores_sorted))\n",
    "        \n",
    "        return population\n",
    "\n",
    "    def fit(self, X, y):\n",
    " \n",
    "        self.chromosomes_best = []\n",
    "        self.scores_best, self.scores_avg  = [], []\n",
    "        \n",
    "        self.dataset = X, y\n",
    "        self.n_features = X.shape[1]\n",
    "        g = 1\n",
    "        population = self.initilize()\n",
    "        for i in range(self.n_gen):\n",
    "            population = self.generate(population)\n",
    "            print('generation:', g)\n",
    "            g+=1\n",
    "        return self \n",
    "    \n",
    "    @property\n",
    "    def support_(self):\n",
    "        return self.chromosomes_best[-1]\n",
    "\n",
    "    def plot_scores(self):\n",
    "        plt.plot(self.scores_best, label='Best')\n",
    "        plt.plot(self.scores_avg, label='Average')\n",
    "        plt.legend()\n",
    "        plt.ylabel('Scores')\n",
    "        plt.xlabel('Generation')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73a616f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), array([ True, False,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True,  True,\n        True,  True, False,  True, False,  True, False,  True, False,\n       False, False,  True,  True, False,  True,  True,  True, False,\n        True,  True,  True,  True, False,  True,  True, False,  True,\n       False,  True, False, False, False,  True,  True, False,  True,\n        True, False, False,  True,  True,  True,  True, False,  True,\n        True, False,  True,  True,  True,  True,  True, False, False,\n        True,  True, False, False,  True,  True, False, False,  True,\n        True, False,  True, False, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True, False,\n        True,  True,  True,  True,  True, False,  True, False,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True, False,  True,  True, False,\n        True, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False, False,\n       False, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True, False,  True, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True, False,  True, False,  True,\n       False,  True, False,  True, False,  True,  True,  True,  True,\n        True, False, False, False,  True, False,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True, False,  True, False,  True,  True,  True,  True, False,\n        True, False, False,  True,  True, False,  True,  True, False,\n        True,  True, False, False,  True, False, False, False,  True,\n       False,  True, False,  True,  True,  True,  True, False, False,\n        True,  True,  True,  True,  True, False,  True,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False,  True, False,  True,\n        True, False,  True,  True,  True,  True,  True, False,  True,\n       False, False, False,  True,  True, False,  True,  True, False,\n       False,  True, False,  True,  True, False,  True, False,  True,\n        True, False,  True,  True, False,  True,  True, False,  True,\n        True, False,  True,  True,  True,  True, False,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n       False,  True, False,  True,  True,  True,  True,  True, False,\n        True,  True, False,  True,  True, False,  True, False, False,\n       False,  True, False, False, False, False,  True,  True, False,\n        True,  True,  True, False, False, False, False,  True,  True,\n        True,  True,  True, False, False,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False, False, False, False,\n        True,  True, False, False, False,  True, False,  True,  True,\n        True,  True, False,  True,  True]))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), array([ True, False,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True,  True,\n        True,  True, False,  True, False,  True, False,  True, False,\n       False, False,  True,  True, False,  True,  True,  True, False,\n        True,  True,  True,  True, False,  True,  True, False,  True,\n       False,  True, False, False, False,  True,  True, False,  True,\n        True, False, False,  True,  True,  True,  True, False,  True,\n        True, False,  True,  True,  True,  True,  True, False, False,\n        True,  True, False, False,  True,  True, False, False,  True,\n        True, False,  True, False, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True, False,\n        True,  True,  True,  True,  True, False,  True, False,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True, False,  True,  True, False,\n        True, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False, False,\n       False, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True, False,  True, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True, False,  True, False,  True,\n       False,  True, False,  True, False,  True,  True,  True,  True,\n        True, False, False, False,  True, False,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True, False,  True, False,  True,  True,  True,  True, False,\n        True, False, False,  True,  True, False,  True,  True, False,\n        True,  True, False, False,  True, False, False, False,  True,\n       False,  True, False,  True,  True,  True,  True, False, False,\n        True,  True,  True,  True,  True, False,  True,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False,  True, False,  True,\n        True, False,  True,  True,  True,  True,  True, False,  True,\n       False, False, False,  True,  True, False,  True,  True, False,\n       False,  True, False,  True,  True, False,  True, False,  True,\n        True, False,  True,  True, False,  True,  True, False,  True,\n        True, False,  True,  True,  True,  True, False,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n       False,  True, False,  True,  True,  True,  True,  True, False,\n        True,  True, False,  True,  True, False,  True, False, False,\n       False,  True, False, False, False, False,  True,  True, False,\n        True,  True,  True, False, False, False, False,  True,  True,\n        True,  True,  True, False, False,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False, False, False, False,\n        True,  True, False, False, False,  True, False,  True,  True,\n        True,  True, False,  True,  True]))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming X is a NumPy array and Y is the target\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sel \u001b[38;5;241m=\u001b[39m GeneticSelector(estimator\u001b[38;5;241m=\u001b[39mSVC(), \n\u001b[0;32m      6\u001b[0m                       n_gen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, n_best\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, n_rand\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, \n\u001b[0;32m      7\u001b[0m                       n_children\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, mutation_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m sel\u001b[38;5;241m.\u001b[39mfit(X, Y)\n",
      "Cell \u001b[1;32mIn[8], line 96\u001b[0m, in \u001b[0;36mGeneticSelector.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     94\u001b[0m population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitilize()\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_gen):\n\u001b[1;32m---> 96\u001b[0m     population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(population)\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneration:\u001b[39m\u001b[38;5;124m'\u001b[39m, g)\n\u001b[0;32m     98\u001b[0m     g\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[8], line 75\u001b[0m, in \u001b[0;36mGeneticSelector.generate\u001b[1;34m(self, population)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, population):\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m# Selection, crossover and mutation\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m     scores_sorted, population_sorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness(population)\n\u001b[0;32m     76\u001b[0m     population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect(population_sorted)\n\u001b[0;32m     77\u001b[0m     population \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrossover(population)\n",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m, in \u001b[0;36mGeneticSelector.fitness\u001b[1;34m(self, population)\u001b[0m\n\u001b[0;32m     33\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chromosome \u001b[38;5;129;01min\u001b[39;00m population:\n\u001b[1;32m---> 35\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cross_val_score(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X[:,chromosome], y, \n\u001b[0;32m     36\u001b[0m                                                cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m     37\u001b[0m                                                scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     38\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[0;32m     39\u001b[0m scores, population \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores), np\u001b[38;5;241m.\u001b[39marray(population) \n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), array([ True, False,  True,  True, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True,  True,\n        True,  True, False,  True, False,  True, False,  True, False,\n       False, False,  True,  True, False,  True,  True,  True, False,\n        True,  True,  True,  True, False,  True,  True, False,  True,\n       False,  True, False, False, False,  True,  True, False,  True,\n        True, False, False,  True,  True,  True,  True, False,  True,\n        True, False,  True,  True,  True,  True,  True, False, False,\n        True,  True, False, False,  True,  True, False, False,  True,\n        True, False,  True, False, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True, False,  True, False,\n        True,  True,  True,  True,  True, False,  True, False,  True,\n        True,  True,  True,  True,  True,  True, False,  True,  True,\n        True,  True,  True,  True,  True, False,  True,  True, False,\n        True, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True, False, False,\n       False, False,  True,  True,  True,  True,  True,  True,  True,\n        True,  True, False,  True, False,  True,  True,  True,  True,\n        True,  True,  True, False,  True,  True,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True, False,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True,  True,  True, False,  True, False,  True, False,  True,\n       False,  True, False,  True, False,  True,  True,  True,  True,\n        True, False, False, False,  True, False,  True, False,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n       False,  True,  True, False,  True,  True,  True,  True,  True,\n        True, False,  True, False,  True,  True,  True,  True, False,\n        True, False, False,  True,  True, False,  True,  True, False,\n        True,  True, False, False,  True, False, False, False,  True,\n       False,  True, False,  True,  True,  True,  True, False, False,\n        True,  True,  True,  True,  True, False,  True,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False,  True, False,  True,\n        True, False,  True,  True,  True,  True,  True, False,  True,\n       False, False, False,  True,  True, False,  True,  True, False,\n       False,  True, False,  True,  True, False,  True, False,  True,\n        True, False,  True,  True, False,  True,  True, False,  True,\n        True, False,  True,  True,  True,  True, False,  True,  True,\n        True, False, False,  True,  True,  True,  True,  True,  True,\n       False,  True, False,  True,  True,  True,  True,  True, False,\n        True,  True, False,  True,  True, False,  True, False, False,\n       False,  True, False, False, False, False,  True,  True, False,\n        True,  True,  True, False, False, False, False,  True,  True,\n        True,  True,  True, False, False,  True,  True,  True,  True,\n       False,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True, False, False, False, False,\n        True,  True, False, False, False,  True, False,  True,  True,\n        True,  True, False,  True,  True]))"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming X is a NumPy array and Y is the target\n",
    "sel = GeneticSelector(estimator=SVC(), \n",
    "                      n_gen=7, size=200, n_best=40, n_rand=40, \n",
    "                      n_children=5, mutation_rate=0.05)\n",
    "sel.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7ed1cdd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sel.plot_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b290f484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV MSE after feature selection: 0.11\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = -1.0 * cross_val_score(est, X[:,sel.support_], Y, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "print(\"CV MSE after feature selection: {:.2f}\".format(np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8515bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(sel, open('ga.pkl', 'wb'))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de470917",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7fc9570e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "42/42 [==============================] - 1s 4ms/step - loss: 0.6822 - accuracy: 0.6284\n",
      "Epoch 2/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6940\n",
      "Epoch 3/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.6398 - accuracy: 0.6932\n",
      "Epoch 4/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6240 - accuracy: 0.6932\n",
      "Epoch 5/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.6932\n",
      "Epoch 6/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.6049 - accuracy: 0.6940\n",
      "Epoch 7/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5979 - accuracy: 0.6925\n",
      "Epoch 8/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5850 - accuracy: 0.6940\n",
      "Epoch 9/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5844 - accuracy: 0.6962\n",
      "Epoch 10/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5667 - accuracy: 0.6992\n",
      "Epoch 11/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.7074\n",
      "Epoch 12/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.5461 - accuracy: 0.7178\n",
      "Epoch 13/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7312\n",
      "Epoch 14/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7535\n",
      "Epoch 15/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7751\n",
      "Epoch 16/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4752 - accuracy: 0.7967\n",
      "Epoch 17/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.8064\n",
      "Epoch 18/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.8131\n",
      "Epoch 19/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.8101\n",
      "Epoch 20/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8250\n",
      "Epoch 21/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4102 - accuracy: 0.8332\n",
      "Epoch 22/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8369\n",
      "Epoch 23/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8414\n",
      "Epoch 24/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8362\n",
      "Epoch 25/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8414\n",
      "Epoch 26/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3854 - accuracy: 0.8354\n",
      "Epoch 27/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3738 - accuracy: 0.8444\n",
      "Epoch 28/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8384\n",
      "Epoch 29/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3707 - accuracy: 0.8526\n",
      "Epoch 30/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3697 - accuracy: 0.8533\n",
      "Epoch 31/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8630\n",
      "Epoch 32/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8444\n",
      "Epoch 33/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.8474\n",
      "Epoch 34/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3494 - accuracy: 0.8533\n",
      "Epoch 35/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3558 - accuracy: 0.8511\n",
      "Epoch 36/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3477 - accuracy: 0.8585\n",
      "Epoch 37/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8526\n",
      "Epoch 38/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3534 - accuracy: 0.8518\n",
      "Epoch 39/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8585\n",
      "Epoch 40/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8578\n",
      "Epoch 41/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3398 - accuracy: 0.8652\n",
      "Epoch 42/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8630\n",
      "Epoch 43/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3274 - accuracy: 0.8660\n",
      "Epoch 44/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3393 - accuracy: 0.8593\n",
      "Epoch 45/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3252 - accuracy: 0.8697\n",
      "Epoch 46/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8704\n",
      "Epoch 47/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3225 - accuracy: 0.8660\n",
      "Epoch 48/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3157 - accuracy: 0.8749\n",
      "Epoch 49/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.8771\n",
      "Epoch 50/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3191 - accuracy: 0.8771\n",
      "Epoch 51/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8779\n",
      "Epoch 52/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3103 - accuracy: 0.8771\n",
      "Epoch 53/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3136 - accuracy: 0.8891\n",
      "Epoch 54/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.3148 - accuracy: 0.8801\n",
      "Epoch 55/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8846\n",
      "Epoch 56/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8846\n",
      "Epoch 57/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8920\n",
      "Epoch 58/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8801\n",
      "Epoch 59/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8838\n",
      "Epoch 60/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2878 - accuracy: 0.8935\n",
      "Epoch 61/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2910 - accuracy: 0.8943\n",
      "Epoch 62/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2867 - accuracy: 0.8928\n",
      "Epoch 63/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8920\n",
      "Epoch 64/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2977 - accuracy: 0.8898\n",
      "Epoch 65/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.8920\n",
      "Epoch 66/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2738 - accuracy: 0.8928\n",
      "Epoch 67/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2752 - accuracy: 0.8965\n",
      "Epoch 68/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2732 - accuracy: 0.8995\n",
      "Epoch 69/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2832 - accuracy: 0.8958\n",
      "Epoch 70/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2751 - accuracy: 0.8995\n",
      "Epoch 71/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8965\n",
      "Epoch 72/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8980\n",
      "Epoch 73/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2653 - accuracy: 0.8995\n",
      "Epoch 74/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.8995\n",
      "Epoch 75/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8980\n",
      "Epoch 76/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.9032\n",
      "Epoch 77/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.9084\n",
      "Epoch 78/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.9054\n",
      "Epoch 79/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.9121\n",
      "Epoch 80/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2537 - accuracy: 0.9099\n",
      "Epoch 81/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2547 - accuracy: 0.9039\n",
      "Epoch 82/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.9099\n",
      "Epoch 83/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2499 - accuracy: 0.8995\n",
      "Epoch 84/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.9121\n",
      "Epoch 85/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.9166\n",
      "Epoch 86/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2387 - accuracy: 0.9092\n",
      "Epoch 87/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.9099\n",
      "Epoch 88/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2390 - accuracy: 0.9084\n",
      "Epoch 89/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2373 - accuracy: 0.9114\n",
      "Epoch 90/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2407 - accuracy: 0.9114\n",
      "Epoch 91/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9159\n",
      "Epoch 92/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.9159\n",
      "Epoch 93/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 0.9151\n",
      "Epoch 94/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2297 - accuracy: 0.9144\n",
      "Epoch 95/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2174 - accuracy: 0.9181\n",
      "Epoch 96/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9159\n",
      "Epoch 97/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9151\n",
      "Epoch 98/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2288 - accuracy: 0.9092\n",
      "Epoch 99/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9241\n",
      "Epoch 100/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9166\n",
      "Epoch 101/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2238 - accuracy: 0.9188\n",
      "Epoch 102/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9173\n",
      "Epoch 103/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2152 - accuracy: 0.9248\n",
      "Epoch 104/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2176 - accuracy: 0.9255\n",
      "Epoch 105/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2219 - accuracy: 0.9203\n",
      "Epoch 106/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2151 - accuracy: 0.9278\n",
      "Epoch 107/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2086 - accuracy: 0.9285\n",
      "Epoch 108/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2276 - accuracy: 0.9136\n",
      "Epoch 109/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9308\n",
      "Epoch 110/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2166 - accuracy: 0.9188\n",
      "Epoch 111/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2088 - accuracy: 0.9285\n",
      "Epoch 112/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2127 - accuracy: 0.9211\n",
      "Epoch 113/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2055 - accuracy: 0.9226\n",
      "Epoch 114/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2000 - accuracy: 0.9293\n",
      "Epoch 115/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1989 - accuracy: 0.9300\n",
      "Epoch 116/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2063 - accuracy: 0.9248\n",
      "Epoch 117/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2038 - accuracy: 0.9218\n",
      "Epoch 118/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2158 - accuracy: 0.9270\n",
      "Epoch 119/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9315\n",
      "Epoch 120/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9285\n",
      "Epoch 121/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.2039 - accuracy: 0.9248\n",
      "Epoch 122/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2085 - accuracy: 0.9263\n",
      "Epoch 123/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9315\n",
      "Epoch 124/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9308\n",
      "Epoch 125/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1907 - accuracy: 0.9315\n",
      "Epoch 126/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.2056 - accuracy: 0.9241\n",
      "Epoch 127/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1893 - accuracy: 0.9337\n",
      "Epoch 128/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1947 - accuracy: 0.9293\n",
      "Epoch 129/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1940 - accuracy: 0.9263\n",
      "Epoch 130/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.2053 - accuracy: 0.9196\n",
      "Epoch 131/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1989 - accuracy: 0.9233\n",
      "Epoch 132/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9315\n",
      "Epoch 133/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1928 - accuracy: 0.9315\n",
      "Epoch 134/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1936 - accuracy: 0.9330\n",
      "Epoch 135/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1831 - accuracy: 0.9427\n",
      "Epoch 136/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1786 - accuracy: 0.9367\n",
      "Epoch 137/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9278\n",
      "Epoch 138/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1890 - accuracy: 0.9337\n",
      "Epoch 139/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1891 - accuracy: 0.9345\n",
      "Epoch 140/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1777 - accuracy: 0.9330\n",
      "Epoch 141/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9293\n",
      "Epoch 142/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1751 - accuracy: 0.9375\n",
      "Epoch 143/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1834 - accuracy: 0.9308\n",
      "Epoch 144/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1727 - accuracy: 0.9397\n",
      "Epoch 145/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1688 - accuracy: 0.9389\n",
      "Epoch 146/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1808 - accuracy: 0.9293\n",
      "Epoch 147/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1849 - accuracy: 0.9337\n",
      "Epoch 148/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1717 - accuracy: 0.9412\n",
      "Epoch 149/175\n",
      "42/42 [==============================] - 0s 5ms/step - loss: 0.1739 - accuracy: 0.9419\n",
      "Epoch 150/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9315\n",
      "Epoch 151/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1681 - accuracy: 0.9397\n",
      "Epoch 152/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1764 - accuracy: 0.9352\n",
      "Epoch 153/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1725 - accuracy: 0.9389\n",
      "Epoch 154/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9442\n",
      "Epoch 155/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1712 - accuracy: 0.9345\n",
      "Epoch 156/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9404\n",
      "Epoch 157/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9404\n",
      "Epoch 158/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9337\n",
      "Epoch 159/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1642 - accuracy: 0.9419\n",
      "Epoch 160/175\n",
      "42/42 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9322\n",
      "Epoch 161/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9397\n",
      "Epoch 162/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9360\n",
      "Epoch 163/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1726 - accuracy: 0.9404\n",
      "Epoch 164/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9486\n",
      "Epoch 165/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9330\n",
      "Epoch 166/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1603 - accuracy: 0.9434\n",
      "Epoch 167/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1678 - accuracy: 0.9389\n",
      "Epoch 168/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9375\n",
      "Epoch 169/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1598 - accuracy: 0.9427\n",
      "Epoch 170/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9360\n",
      "Epoch 171/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9427\n",
      "Epoch 172/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9434\n",
      "Epoch 173/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1594 - accuracy: 0.9412\n",
      "Epoch 174/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9360\n",
      "Epoch 175/175\n",
      "42/42 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9427\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4219 - accuracy: 0.8690\n",
      "\n",
      "loss: 42.19%\n",
      "\n",
      "accuracy: 86.90%\n"
     ]
    }
   ],
   "source": [
    "AN = Sequential()\n",
    "AN.add(Dense(256, input_dim=271, activation='relu'))  # Updated input_dim to match the actual number of features\n",
    "AN.add(Dropout(0.2))\n",
    "AN.add(Dense(128, activation='relu'))\n",
    "AN.add(Dropout(0.2))\n",
    "AN.add(Dense(128, activation='relu'))\n",
    "AN.add(Dropout(0.3))\n",
    "AN.add(Dense(32, activation='relu'))\n",
    "AN.add(Dropout(0.2))\n",
    "AN.add(Dense(1, activation='sigmoid'))\n",
    "AN.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "AN.fit(X_train[:, sel.support_], y_train, epochs=175, batch_size=32)\n",
    "\n",
    "scores = AN.evaluate(X_test[:, sel.support_], y_test)\n",
    "for i in range(len(scores)):\n",
    "    print(\"\\n%s: %.2f%%\" % (AN.metrics_names[i], scores[i]*100))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8eea85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from androguard.core.bytecodes.apk import APK\n",
    "\n",
    "def predict(apk):\n",
    "  vector = {}\n",
    "  a = APK(apk)\n",
    "  perm = a.get_permissions()\n",
    "  print(perm)\n",
    "  for d in features:\n",
    "    if d in perm:\n",
    "      vector[d]=1\n",
    "    else:\n",
    "      vector[d]=0\n",
    "  data = [ v for v in vector.values() ]\n",
    "  data = np.array(data)\n",
    "  # print(data[sel.support_])\n",
    "  print(AN.predict([[data[sel.support_]]]))\n",
    "\n",
    "#predict('/content/drive/My Drive/Android-Malware-Detection/dataset/malign/com.prasesfee.apk')\n",
    "#predict('/content/drive/My Drive/Android-Malware-Detection/dataset/benign/com.whatsapp.apk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b1ee451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(AN, open('ANN_GA.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a91b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = dataset['class']\n",
    "X = dataset.drop(['class'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "37019f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.680 total time=   0.1s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.684 total time=   0.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.687 total time=   0.0s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.679 total time=   0.1s\n",
      "[CV 1/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.632 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.706 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.660 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=1, kernel=sigmoid;, score=0.631 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.825 total time=   0.0s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.829 total time=   0.0s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.810 total time=   0.0s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.825 total time=   0.0s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.817 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.792 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.818 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.792 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.817 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.1, kernel=sigmoid;, score=0.810 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.717 total time=   0.1s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.706 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.714 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.716 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.709 total time=   0.1s\n",
      "[CV 1/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.01, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.680 total time=   0.1s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END .C=0.1, gamma=0.001, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.1s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.1s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.1s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.1s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, gamma=0.0001, kernel=linear;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.844 total time=   0.1s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.851 total time=   0.0s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.862 total time=   0.1s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.854 total time=   0.1s\n",
      "[CV 1/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.558 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.550 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.612 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=1, kernel=sigmoid;, score=0.567 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.848 total time=   0.0s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.881 total time=   0.2s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.866 total time=   0.1s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.877 total time=   0.2s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.840 total time=   0.2s\n",
      "[CV 1/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.807 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.796 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.802 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.1, kernel=sigmoid;, score=0.780 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.848 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.833 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.814 total time=   0.3s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.836 total time=   0.1s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.825 total time=   0.1s\n",
      "[CV 1/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.799 total time=   0.1s\n",
      "[CV 2/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.784 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.01, kernel=sigmoid;, score=0.813 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.747 total time=   0.1s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.725 total time=   0.1s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.732 total time=   0.1s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.731 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.735 total time=   0.1s\n",
      "[CV 1/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=0.001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END ...C=1, gamma=0.001, kernel=linear;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 3/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END .C=1, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, gamma=0.0001, kernel=linear;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.862 total time=   0.1s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.851 total time=   0.0s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.847 total time=   0.1s\n",
      "[CV 1/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.546 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.616 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=1, kernel=sigmoid;, score=0.567 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=1, kernel=linear;, score=0.851 total time=   0.1s\n",
      "[CV 2/5] END ......C=10, gamma=1, kernel=linear;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END ......C=10, gamma=1, kernel=linear;, score=0.851 total time=   0.2s\n",
      "[CV 4/5] END ......C=10, gamma=1, kernel=linear;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=1, kernel=linear;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.874 total time=   0.0s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.899 total time=   0.0s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.866 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.736 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.758 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.784 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, gamma=0.1, kernel=sigmoid;, score=0.769 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.851 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.851 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.1, kernel=linear;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.858 total time=   0.0s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END ..C=10, gamma=0.01, kernel=sigmoid;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.851 total time=   0.1s\n",
      "[CV 2/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.851 total time=   0.2s\n",
      "[CV 4/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.858 total time=   0.1s\n",
      "[CV 5/5] END ...C=10, gamma=0.01, kernel=linear;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.825 total time=   0.1s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.784 total time=   0.0s\n",
      "[CV 4/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END .C=10, gamma=0.001, kernel=sigmoid;, score=0.813 total time=   0.0s\n",
      "[CV 1/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.851 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.840 total time=   0.2s\n",
      "[CV 3/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.851 total time=   0.2s\n",
      "[CV 4/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.858 total time=   0.1s\n",
      "[CV 5/5] END ..C=10, gamma=0.001, kernel=linear;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.751 total time=   0.1s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.740 total time=   0.1s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.732 total time=   0.1s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.731 total time=   0.1s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.735 total time=   0.1s\n",
      "[CV 1/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 2/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.1s\n",
      "[CV 3/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.680 total time=   0.0s\n",
      "[CV 4/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.0s\n",
      "[CV 5/5] END C=10, gamma=0.0001, kernel=sigmoid;, score=0.679 total time=   0.1s\n",
      "[CV 1/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.851 total time=   0.0s\n",
      "[CV 2/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.851 total time=   0.2s\n",
      "[CV 4/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.858 total time=   0.1s\n",
      "[CV 5/5] END .C=10, gamma=0.0001, kernel=linear;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.836 total time=   0.1s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.847 total time=   0.1s\n",
      "[CV 1/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.546 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.612 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=1, kernel=sigmoid;, score=0.571 total time=   0.0s\n",
      "[CV 1/5] END .....C=100, gamma=1, kernel=linear;, score=0.829 total time=   1.9s\n",
      "[CV 2/5] END .....C=100, gamma=1, kernel=linear;, score=0.848 total time=   0.4s\n",
      "[CV 3/5] END .....C=100, gamma=1, kernel=linear;, score=0.848 total time=   0.7s\n",
      "[CV 4/5] END .....C=100, gamma=1, kernel=linear;, score=0.851 total time=   0.6s\n",
      "[CV 5/5] END .....C=100, gamma=1, kernel=linear;, score=0.817 total time=   1.1s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.874 total time=   0.0s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.859 total time=   0.0s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.884 total time=   0.0s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.843 total time=   0.1s\n",
      "[CV 1/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.740 total time=   0.0s\n",
      "[CV 2/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.799 total time=   0.0s\n",
      "[CV 3/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.755 total time=   0.0s\n",
      "[CV 4/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END ..C=100, gamma=0.1, kernel=sigmoid;, score=0.776 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.829 total time=   1.5s\n",
      "[CV 2/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.848 total time=   0.3s\n",
      "[CV 3/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.848 total time=   0.5s\n",
      "[CV 4/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.851 total time=   0.5s\n",
      "[CV 5/5] END ...C=100, gamma=0.1, kernel=linear;, score=0.817 total time=   0.9s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.866 total time=   0.0s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.881 total time=   0.0s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.844 total time=   0.0s\n",
      "[CV 4/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.866 total time=   0.0s\n",
      "[CV 5/5] END .C=100, gamma=0.01, kernel=sigmoid;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.829 total time=   1.4s\n",
      "[CV 2/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.848 total time=   0.3s\n",
      "[CV 3/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.848 total time=   0.5s\n",
      "[CV 4/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.851 total time=   0.5s\n",
      "[CV 5/5] END ..C=100, gamma=0.01, kernel=linear;, score=0.817 total time=   1.0s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.859 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.001, kernel=sigmoid;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END .C=100, gamma=0.001, kernel=linear;, score=0.829 total time=   1.7s\n",
      "[CV 2/5] END .C=100, gamma=0.001, kernel=linear;, score=0.848 total time=   0.4s\n",
      "[CV 3/5] END .C=100, gamma=0.001, kernel=linear;, score=0.848 total time=   0.6s\n",
      "[CV 4/5] END .C=100, gamma=0.001, kernel=linear;, score=0.851 total time=   0.6s\n",
      "[CV 5/5] END .C=100, gamma=0.001, kernel=linear;, score=0.817 total time=   1.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.825 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.799 total time=   0.0s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.807 total time=   0.0s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.784 total time=   0.0s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.821 total time=   0.0s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=sigmoid;, score=0.813 total time=   0.0s\n",
      "[CV 1/5] END C=100, gamma=0.0001, kernel=linear;, score=0.829 total time=   1.4s\n",
      "[CV 2/5] END C=100, gamma=0.0001, kernel=linear;, score=0.848 total time=   0.3s\n",
      "[CV 3/5] END C=100, gamma=0.0001, kernel=linear;, score=0.848 total time=   0.5s\n",
      "[CV 4/5] END C=100, gamma=0.0001, kernel=linear;, score=0.851 total time=   0.6s\n",
      "[CV 5/5] END C=100, gamma=0.0001, kernel=linear;, score=0.817 total time=   1.1s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.840 total time=   0.1s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.851 total time=   0.1s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.847 total time=   0.0s\n",
      "[CV 1/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.550 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.621 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.546 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.612 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=1, kernel=sigmoid;, score=0.578 total time=   0.0s\n",
      "[CV 1/5] END ....C=1000, gamma=1, kernel=linear;, score=0.833 total time=   3.8s\n",
      "[CV 2/5] END ....C=1000, gamma=1, kernel=linear;, score=0.844 total time=   4.2s\n",
      "[CV 3/5] END ....C=1000, gamma=1, kernel=linear;, score=0.848 total time=   1.9s\n",
      "[CV 4/5] END ....C=1000, gamma=1, kernel=linear;, score=0.862 total time=   5.7s\n",
      "[CV 5/5] END ....C=1000, gamma=1, kernel=linear;, score=0.825 total time=   5.0s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 1/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.725 total time=   0.0s\n",
      "[CV 2/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.796 total time=   0.0s\n",
      "[CV 3/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.747 total time=   0.0s\n",
      "[CV 4/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.776 total time=   0.0s\n",
      "[CV 5/5] END .C=1000, gamma=0.1, kernel=sigmoid;, score=0.772 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.833 total time=   3.7s\n",
      "[CV 2/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.844 total time=   4.7s\n",
      "[CV 3/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.848 total time=   2.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.862 total time=   5.8s\n",
      "[CV 5/5] END ..C=1000, gamma=0.1, kernel=linear;, score=0.825 total time=   5.4s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.870 total time=   0.0s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.862 total time=   0.0s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.892 total time=   0.0s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.869 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.851 total time=   0.1s\n",
      "[CV 2/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.844 total time=   0.1s\n",
      "[CV 3/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.855 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.01, kernel=sigmoid;, score=0.806 total time=   0.0s\n",
      "[CV 1/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.833 total time=   3.7s\n",
      "[CV 2/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.844 total time=   4.0s\n",
      "[CV 3/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.848 total time=   1.9s\n",
      "[CV 4/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.862 total time=   5.7s\n",
      "[CV 5/5] END .C=1000, gamma=0.01, kernel=linear;, score=0.825 total time=   4.6s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.851 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.844 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.873 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.825 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.840 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.855 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.848 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.862 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=sigmoid;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.001, kernel=linear;, score=0.833 total time=   3.7s\n",
      "[CV 2/5] END C=1000, gamma=0.001, kernel=linear;, score=0.844 total time=   4.0s\n",
      "[CV 3/5] END C=1000, gamma=0.001, kernel=linear;, score=0.848 total time=   1.9s\n",
      "[CV 4/5] END C=1000, gamma=0.001, kernel=linear;, score=0.862 total time=   5.8s\n",
      "[CV 5/5] END C=1000, gamma=0.001, kernel=linear;, score=0.825 total time=   4.6s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.836 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.859 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.840 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.854 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.828 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.862 total time=   0.0s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.847 total time=   0.0s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=sigmoid;, score=0.832 total time=   0.0s\n",
      "[CV 1/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.833 total time=   3.7s\n",
      "[CV 2/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.844 total time=   4.0s\n",
      "[CV 3/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.848 total time=   2.2s\n",
      "[CV 4/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.862 total time=   5.8s\n",
      "[CV 5/5] END C=1000, gamma=0.0001, kernel=linear;, score=0.825 total time=   5.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10, 100, 1000],\n",
       "                         &#x27;gamma&#x27;: [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;, &#x27;sigmoid&#x27;, &#x27;linear&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf', 'sigmoid', 'linear']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining parameter range \n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "\t\t\t'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "\t\t\t'kernel': ['rbf','sigmoid', 'linear']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \n",
    "# fitting the model for grid search \n",
    "grid.fit(X_train.loc[:, sel.support_], y_train)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a32a42cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.92      0.95      0.94       237\n",
      "      malign       0.87      0.81      0.84        99\n",
      "\n",
      "    accuracy                           0.91       336\n",
      "   macro avg       0.90      0.88      0.89       336\n",
      "weighted avg       0.91      0.91      0.91       336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_) \n",
    "grid_predictions = grid.predict(X_test.loc[:,sel.support_]) \n",
    "\n",
    "# print classification report \n",
    "print(classification_report(y_test, grid_predictions)) \n",
    "pickle.dump(grid, open('svc_ga.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "659a3b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(apk):\n",
    "  vector = {}\n",
    "  a = APK(apk)\n",
    "  perm = a.get_permissions()\n",
    "  print(perm)\n",
    "  for d in features:\n",
    "    if d in perm:\n",
    "      vector[d]=1\n",
    "    else:\n",
    "      vector[d]=0\n",
    "  data = [ v for v in vector.values() ]\n",
    "  data = np.array(data)\n",
    "  print(grid.predict([data[sel.support_]]))\n",
    "\n",
    "#predict('/content/Ransomware/PornDroid/1c53e2c34d1219a2fae8fcf8ec872ac8.apk')\n",
    "#predict('/content/drive/My Drive/Android-Malware-Detection/dataset/benign/com.whatsapp.apk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46bea4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
